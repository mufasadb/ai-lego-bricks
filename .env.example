# ==============================================================================
# Beachy's Project Assistant - Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your actual values
# Never commit .env to version control - it contains secrets!

# ==============================================================================
# CLOUDFLARE ACCESS CREDENTIALS
# ==============================================================================
# Used for accessing services behind Cloudflare Access
# Get these from your Cloudflare Zero Trust dashboard
CF_ACCESS_CLIENT_ID=your_cloudflare_client_id_here
CF_ACCESS_CLIENT_SECRET=your_cloudflare_client_secret_here

# ==============================================================================
# OLLAMA CONFIGURATION
# ==============================================================================
# Local or remote Ollama instance for running LLMs
OLLAMA_URL=http://localhost:11434
# Default model to use if none specified
OLLAMA_DEFAULT_MODEL=llama2

# ==============================================================================
# NEO4J CONFIGURATION
# ==============================================================================
# Graph database for advanced memory storage and relationships
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password_here

# ==============================================================================
# GOOGLE AI STUDIO / GEMINI CONFIGURATION
# ==============================================================================
# Google's Gemini AI for chat functionality
# Get API key from: https://makersuite.google.com/app/apikey
GOOGLE_AI_STUDIO_KEY=your_google_ai_studio_key_here
GEMINI_DEFAULT_MODEL=gemini-1.5-flash
GEMINI_API_BASE_URL=https://generativelanguage.googleapis.com/v1beta

# ==============================================================================
# SUPABASE CONFIGURATION
# ==============================================================================
# Postgres database with pgvector extensions for memory storage
# Get these from your Supabase project settings > API
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_supabase_anon_key_here

# Note: Use the ANON key (starts with eyJ...), NOT the service role key
# The anon key is safe for client-side use and respects Row Level Security

# ==============================================================================
# AI/ML CONFIGURATION
# ==============================================================================
# Sentence transformer model for generating embeddings
# Options: all-MiniLM-L6-v2, all-mpnet-base-v2, multi-qa-MiniLM-L6-cos-v1
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ==============================================================================
# TEXT-TO-SPEECH (TTS) CONFIGURATION
# ==============================================================================
# Configure one or more TTS providers for voice synthesis

# Coqui-XTTS Local Server
# Set this to your local or remote Coqui-XTTS instance
COQUI_XTTS_URL=http://100.83.40.11:8001

# OpenAI TTS API
# Get API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your_openai_api_key_here

# Google Cloud Text-to-Speech
# Set path to your service account credentials JSON file
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account-key.json

# ==============================================================================
# OPTIONAL: DEVELOPMENT SETTINGS
# ==============================================================================
# Uncomment and modify these for development/debugging

# Log level for application logging
# LOG_LEVEL=INFO

# API request timeout in seconds
# API_TIMEOUT=60

# Maximum tokens for LLM responses
# MAX_TOKENS=1000

# Temperature for LLM responses (0.0 to 1.0)
# TEMPERATURE=0.7

# ==============================================================================
# SETUP INSTRUCTIONS
# ==============================================================================
#
# 1. OLLAMA SETUP:
#    - Install Ollama: https://ollama.ai/
#    - Run: ollama pull llama2
#    - Set OLLAMA_URL to your instance
#
# 2. NEO4J SETUP:
#    - Install Neo4j Desktop or use Docker
#    - Create a database with a password
#    - Set NEO4J_URI and NEO4J_PASSWORD
#
# 3. GOOGLE AI STUDIO:
#    - Go to https://makersuite.google.com/app/apikey
#    - Create an API key
#    - Set GOOGLE_AI_STUDIO_KEY
#
# 4. SUPABASE SETUP:
#    - Create project at https://supabase.com
#    - Go to Settings > API
#    - Copy URL and anon key (NOT service role key)
#    - Set SUPABASE_URL and SUPABASE_ANON_KEY
#    - Run setup_supabase_pgvector.sql in SQL Editor
#    - Run: python setup_supabase.py to verify
#
# 5. EMBEDDING MODEL:
#    - First run will download the model automatically
#    - Models are cached locally after first download
#
# 6. TTS SETUP (Choose one or more):
#    - COQUI-XTTS: Install and run local server, set COQUI_XTTS_URL
#    - OPENAI TTS: Get API key from OpenAI, set OPENAI_API_KEY
#    - GOOGLE TTS: Set up Google Cloud credentials, set GOOGLE_APPLICATION_CREDENTIALS
#
# ==============================================================================
# SECURITY NOTES
# ==============================================================================
#
# - Never commit .env files to version control
# - Use strong passwords for all services
# - Regularly rotate API keys
# - Consider using environment-specific configurations
# - For production, use proper secret management systems
#