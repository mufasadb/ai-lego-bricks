{
  "name": "conversation_chat_agent",
  "description": "A chat agent that maintains conversation memory using threads",
  "config": {
    "memory_backend": "auto",
    "default_llm_provider": "gemini",
    "default_model": "gemini-1.5-flash"
  },
  "steps": [
    {
      "id": "start_conversation",
      "type": "start_conversation",
      "description": "Initialize a new conversation thread",
      "config": {
        "conversation_id": "main_chat",
        "name": "User Chat Session",
        "system_message": "You are a helpful AI assistant. Be concise but friendly in your responses."
      },
      "outputs": ["conversation_id", "message_count"]
    },
    {
      "id": "get_user_input",
      "type": "input",
      "description": "Get user's message",
      "config": {
        "prompt": "What would you like to ask?"
      },
      "outputs": ["user_query"]
    },
    {
      "id": "continue_conversation",
      "type": "continue_conversation",
      "description": "Continue the conversation with user input and AI response",
      "config": {
        "provider": "gemini",
        "model": "gemini-1.5-flash",
        "conversation_id": "main_chat",
        "include_system_messages": true,
        "history_limit": 10
      },
      "inputs": {
        "message": {
          "from_step": "get_user_input",
          "field": "user_query"
        }
      },
      "outputs": ["assistant_response", "total_messages"]
    },
    {
      "id": "output_response",
      "type": "output",
      "description": "Return the AI's response",
      "config": {
        "format": "text"
      },
      "inputs": {
        "response": {
          "from_step": "continue_conversation",
          "field": "assistant_response"
        },
        "message_count": {
          "from_step": "continue_conversation",
          "field": "total_messages"
        }
      }
    }
  ]
}