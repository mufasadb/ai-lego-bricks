# Project Structure

## ğŸ“ Organized Code Structure

The codebase has been organized into logical folders for better maintainability and easy setup:

```
/Beachys-project-assistant/
â”œâ”€â”€ setup/                         # ğŸ”§ Setup and configuration
â”‚   â”œâ”€â”€ README.md                 # Complete setup guide
â”‚   â”œâ”€â”€ SUPABASE_SETUP.md         # Detailed Supabase instructions
â”‚   â”œâ”€â”€ setup_supabase.py         # Supabase verification script
â”‚   â””â”€â”€ setup_supabase_pgvector.sql # Database schema setup
â”œâ”€â”€ llm/                           # ğŸ¤– LLM abstraction layer
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ llm_client_factory.py     # Factory for creating LLM clients
â”‚   â”œâ”€â”€ text_clients.py           # Text generation clients (Gemini, Ollama)
â”‚   â”œâ”€â”€ vision_clients.py         # Vision analysis clients
â”‚   â”œâ”€â”€ embedding_client.py       # Embedding generation
â”‚   â”œâ”€â”€ model_manager.py          # Model switching and management
â”‚   â”œâ”€â”€ llm_types.py              # Type definitions and enums
â”‚   â””â”€â”€ providers/                # Provider-specific implementations
â”œâ”€â”€ memory/                        # ğŸ§  Memory service package
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ memory_service.py         # Abstract base class & Memory dataclass
â”‚   â”œâ”€â”€ memory_factory.py         # Factory for creating memory services
â”‚   â”œâ”€â”€ neo4j_memory_service.py   # Neo4j implementation
â”‚   â”œâ”€â”€ supabase_memory_service.py # Supabase + pgvector implementation  
â”‚   â””â”€â”€ memory_example.py         # Usage examples and demos
â”œâ”€â”€ pdf_to_text/                   # ğŸ“„ Document processing package
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ pdf_to_text_service.py    # PDF extraction with LLM enhancement
â”‚   â”œâ”€â”€ pdf_extract_options.py    # Configuration for extraction options
â”‚   â””â”€â”€ example_usage.py          # PDF processing examples
â”œâ”€â”€ chunking/                      # âœ‚ï¸ Text chunking service
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ chunking_service.py       # Intelligent text segmentation
â”‚   â”œâ”€â”€ chunking_config.py        # Configuration for chunking strategies
â”‚   â””â”€â”€ example_usage.py          # Chunking usage examples
â”œâ”€â”€ chat/                          # ğŸ’¬ Chat service package
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ chat_service.py           # LLM integrations (Ollama, Gemini)
â”‚   â””â”€â”€ example_usage.py          # Chat usage examples
â”œâ”€â”€ agent_orchestration/           # ğŸ­ Agent orchestration system
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ orchestrator.py           # Main orchestration classes
â”‚   â”œâ”€â”€ models.py                 # Pydantic models for configuration
â”‚   â”œâ”€â”€ step_handlers.py          # Step-specific execution logic
â”‚   â”œâ”€â”€ schemas/                  # JSON schemas for validation
â”‚   â”‚   â””â”€â”€ workflow_schema.json  # Workflow configuration schema
â”‚   â””â”€â”€ examples/                 # Example workflows and usage
â”‚       â”œâ”€â”€ simple_chat_agent.json
â”‚       â”œâ”€â”€ document_analysis_agent.json
â”‚       â”œâ”€â”€ research_agent.json
â”‚       â””â”€â”€ usage_example.py
â”œâ”€â”€ claude-knowledge/              # ğŸ¤– Claude-specific documentation
â”‚   â”œâ”€â”€ CLAUDE.md                 # Claude guidelines and project overview
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md      # This file - project structure docs
â”‚   â””â”€â”€ README.md                 # Knowledge base overview
â”œâ”€â”€ test/                          # ğŸ§ª Test suite
â”‚   â”œâ”€â”€ __init__.py               # Test package
â”‚   â”œâ”€â”€ test_delete_operations.py # Delete functionality tests
â”‚   â”œâ”€â”€ test_bulk_delete.py       # Bulk delete tests
â”‚   â””â”€â”€ test_chunking_service.py  # Chunking service tests
â”œâ”€â”€ README.md                      # ğŸ“– Main project documentation
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env.example                   # ğŸ“ Environment template
â”œâ”€â”€ .env                          # ğŸ” Environment configuration (user creates)
â””â”€â”€ CLAUDE.md                     # ğŸ¤– Claude-specific instructions
```

## ğŸš€ How to Use

### First Time Setup
```bash
# 1. Copy environment template
cp .env.example .env

# 2. Follow setup guide
cat setup/README.md

# 3. Verify Supabase setup (if using Supabase)
python setup/setup_supabase.py
```

### Agent Orchestration System (Primary Interface)
```bash
# Run example orchestration workflows
python agent_orchestration/examples/usage_example.py

# Create custom workflows with JSON configuration
```
```python
from agent_orchestration import AgentOrchestrator

# Create orchestrator
orchestrator = AgentOrchestrator()

# Load workflow from JSON
workflow = orchestrator.load_workflow_from_file("my_agent.json")

# Execute with inputs
result = orchestrator.execute_workflow(workflow, {
    "document_path": "/path/to/document.pdf",
    "user_query": "What are the main findings?"
})
```

### LLM Services
```bash
# Run LLM examples
python llm/model_switching_example.py

# Test vision capabilities
python llm/vision_example.py
```
```python
from llm import LLMClientFactory, LLMProvider, VisionProvider

# Create text client
factory = LLMClientFactory()
text_client = factory.create_text_client(LLMProvider.GEMINI)
response = text_client.chat("Hello, world!")

# Create vision client
vision_client = factory.create_vision_client(VisionProvider.GEMINI_VISION)
analysis = vision_client.analyze_image("image.jpg", "Describe this image")
```

### Memory Service
```bash
# Run memory examples
python memory/memory_example.py
```
```python
from memory import create_memory_service
memory_service = create_memory_service("auto")  # Auto-detects available services
```

### Document Processing
```bash
# Run PDF processing examples
python pdf_to_text/example_usage.py
```
```python
from pdf_to_text import PDFToTextService
pdf_service = PDFToTextService()
result = pdf_service.extract_text_with_llm_enhancement("document.pdf")
```

### Text Chunking
```bash
# Run chunking examples
python chunking/example_usage.py
```
```python
from chunking import ChunkingService, ChunkingConfig
chunking_service = ChunkingService(ChunkingConfig(target_size=1000))
chunks = chunking_service.chunk_text("Your long text here...")
```

### Chat Interface
```bash
# Run chat examples
python chat/example_usage.py
```
```python
from chat import ChatService
chat_service = ChatService("gemini")
response = chat_service.chat("Hello, how are you?")
```

### Running Tests
```bash
# Test delete operations
python test/test_delete_operations.py

# Test bulk delete functionality  
python test/test_bulk_delete.py

# Test chunking service
python test/test_chunking_service.py
```

## âœ… What Works

### Agent Orchestration System
- âœ… **JSON-driven workflows:** Define complex agent behavior through configuration
- âœ… **Step-by-step execution:** Clear data flow between operations
- âœ… **Service integration:** Combines all building blocks seamlessly
- âœ… **Error handling:** Comprehensive error reporting and graceful fallbacks
- âœ… **Input/output mapping:** Flexible data passing between steps
- âœ… **Example workflows:** Chat agent, document analysis, research agent
- âœ… **Extensible:** Easy to add new step types and handlers

### LLM Abstraction Layer
- âœ… **Multi-provider support:** Gemini and Ollama integration
- âœ… **Text generation:** Chat and completion capabilities
- âœ… **Vision analysis:** Image analysis with Gemini Vision
- âœ… **Embedding generation:** Text vectorization for similarity search
- âœ… **Model switching:** Runtime model changes without client recreation
- âœ… **Factory pattern:** Consistent interface across providers
- âœ… **Configuration management:** Flexible model and parameter configuration

### Document Processing
- âœ… **PDF extraction:** Traditional and LLM-enhanced text extraction
- âœ… **Vision fallback:** LLM vision for challenging PDFs
- âœ… **Content enhancement:** LLM-powered formatting improvement
- âœ… **Semantic analysis:** Document classification and key point extraction
- âœ… **RAG integration:** Automatic chunking for vector databases
- âœ… **Configurable options:** Flexible extraction strategies

### Text Chunking Service
- âœ… **Boundary preservation:** Respects paragraphs, sentences, and words
- âœ… **Configurable strategies:** Target size with tolerance ranges
- âœ… **Fallback hierarchy:** Graceful degradation from paragraph â†’ sentence â†’ word â†’ character
- âœ… **Integration ready:** Used by PDF service for RAG applications
- âœ… **Semantic awareness:** Preserves meaning across chunk boundaries

### Memory Service Features
- âœ… **Auto-detection:** Finds available services (Neo4j/Supabase)
- âœ… **Neo4j support:** Graph database with relationships
- âœ… **Supabase + pgvector:** PostgreSQL with vector similarity search
- âœ… **Vector search:** Semantic similarity with embeddings
- âœ… **Hybrid search:** Combined vector and text search (Supabase)
- âœ… **CRUD operations:** Create, read, update, delete memories
- âœ… **Bulk operations:** Efficient multi-delete with single query
- âœ… **Search-based delete:** Delete by query criteria
- âœ… **Metadata support:** Structured data with JSON serialization
- âœ… **Pydantic models:** Type-safe data validation and serialization

### Chat Interface
- âœ… **Multi-provider support:** Ollama and Gemini integration
- âœ… **History management:** Automatic conversation tracking
- âœ… **Message format:** Standardized ChatMessage structure
- âœ… **Backward compatibility:** Legacy adapter for existing code

### Testing & Quality
- âœ… **Comprehensive tests:** All core operations validated
- âœ… **Error handling:** Invalid inputs, missing services, network issues
- âœ… **Data integrity:** Relationships cleaned up, search consistency
- âœ… **Performance:** Bulk operations use optimized queries
- âœ… **Type safety:** Pydantic models throughout for validation

## ğŸ”§ Configuration

### Environment Variables
```bash
# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687      # or your Neo4j server
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password

# Supabase Configuration (with pgvector)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key      # NOT service role key

# AI/ML Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2     # Sentence transformer model
```

### Setup Instructions
For detailed setup instructions, see the setup folder:

```bash
# Complete setup guide
cat setup/README.md

# Supabase-specific setup
cat setup/SUPABASE_SETUP.md

# Verify Supabase configuration
python setup/setup_supabase.py
```

The setup process includes:
1. **Environment Configuration** - Copy .env.example to .env
2. **Database Setup** - Choose between Supabase (recommended) or Neo4j
3. **API Keys** - Configure Ollama, Gemini, or other LLM services
4. **Verification** - Test all connections and functionality

## ğŸ“¦ Benefits of Current Structure

1. **Easy Setup:** Dedicated setup folder with comprehensive guides
2. **Modularity:** Clear separation of concerns (setup, memory, chat, tests)
3. **Maintainability:** Easier to find and modify code
4. **User-Friendly:** New users can get started quickly with setup/README.md
5. **Testing:** Isolated test suite with comprehensive coverage
6. **Reusability:** Memory package can be imported elsewhere
7. **Scalability:** Easy to add new services (Redis, Elasticsearch, etc.)
8. **Clean imports:** Proper Python package structure
9. **Documentation:** Multiple levels of documentation for different needs
10. **Production-Ready:** Includes environment templates, verification scripts

## ğŸ¯ Project Philosophy

This project follows a **learning-focused development approach**:

- **Educational:** Each component helps users understand LLM project patterns
- **Well-documented:** Clear explanations and examples throughout
- **Modular:** Easy to extend, modify, and understand
- **Partnership-focused:** Claude acts as a thoughtful development partner

The codebase is now production-ready with a clean, organized structure that prioritizes both functionality and user experience! ğŸ‰