# Project Structure

## ğŸ“ Organized Code Structure

The codebase has been organized into logical folders for better maintainability and easy setup:

```
/Beachys-project-assistant/
â”œâ”€â”€ setup/                         # ğŸ”§ Setup and configuration
â”‚   â”œâ”€â”€ README.md                 # Complete setup guide
â”‚   â”œâ”€â”€ SUPABASE_SETUP.md         # Detailed Supabase instructions
â”‚   â”œâ”€â”€ setup_supabase.py         # Supabase verification script
â”‚   â””â”€â”€ setup_supabase_pgvector.sql # Database schema setup
â”œâ”€â”€ credentials/                   # ğŸ” Secure credential management â­ NEW
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â””â”€â”€ credential_manager.py     # Credential management with library safety
â”œâ”€â”€ llm/                           # ğŸ¤– LLM abstraction layer
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ llm_client_factory.py     # Factory for creating LLM clients
â”‚   â”œâ”€â”€ text_clients.py           # Text generation clients (Gemini, Ollama)
â”‚   â”œâ”€â”€ vision_clients.py         # Vision analysis clients
â”‚   â”œâ”€â”€ embedding_client.py       # Embedding generation
â”‚   â”œâ”€â”€ model_manager.py          # Model switching and management
â”‚   â”œâ”€â”€ llm_types.py              # Type definitions and enums
â”‚   â””â”€â”€ providers/                # Provider-specific implementations
â”œâ”€â”€ memory/                        # ğŸ§  Memory service package
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ memory_service.py         # Abstract base class & Memory dataclass
â”‚   â”œâ”€â”€ memory_factory.py         # Factory for creating memory services
â”‚   â”œâ”€â”€ neo4j_memory_service.py   # Neo4j implementation
â”‚   â”œâ”€â”€ supabase_memory_service.py # Supabase + pgvector implementation  
â”‚   â””â”€â”€ memory_example.py         # Usage examples and demos
â”œâ”€â”€ pdf_to_text/                   # ğŸ“„ Document processing package
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ pdf_to_text_service.py    # PDF extraction with LLM enhancement
â”‚   â”œâ”€â”€ pdf_extract_options.py    # Configuration for extraction options
â”‚   â””â”€â”€ example_usage.py          # PDF processing examples
â”œâ”€â”€ chunking/                      # âœ‚ï¸ Text chunking service
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ chunking_service.py       # Intelligent text segmentation
â”‚   â”œâ”€â”€ chunking_config.py        # Configuration for chunking strategies
â”‚   â””â”€â”€ example_usage.py          # Chunking usage examples
â”œâ”€â”€ chat/                          # ğŸ’¬ Chat service package
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ chat_service.py           # LLM integrations (Ollama, Gemini)
â”‚   â””â”€â”€ example_usage.py          # Chat usage examples
â”œâ”€â”€ prompt/                        # ğŸ¯ Prompt management system
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ prompt_service.py         # Main prompt management service
â”‚   â”œâ”€â”€ prompt_models.py          # Pydantic models for prompts
â”‚   â”œâ”€â”€ prompt_storage.py         # Storage backends (Supabase, file)
â”‚   â”œâ”€â”€ prompt_registry.py        # Registry with caching
â”‚   â”œâ”€â”€ evaluation_service.py     # Evaluation and A/B testing
â”‚   â”œâ”€â”€ concept_eval_models.py    # ğŸ†• Concept evaluation data models
â”‚   â”œâ”€â”€ concept_eval_storage.py   # ğŸ†• Storage for evaluations and results
â”‚   â”œâ”€â”€ concept_judge.py          # ğŸ†• LLM-as-judge service
â”‚   â”œâ”€â”€ concept_evaluation_service.py  # ğŸ†• Main evaluation orchestration
â”‚   â”œâ”€â”€ eval_builder.py           # ğŸ†• Builder tools and templates
â”‚   â”œâ”€â”€ example_usage.py          # Usage examples and demos
â”‚   â”œâ”€â”€ README.md                 # Comprehensive documentation
â”‚   â””â”€â”€ README_CONCEPT_EVAL.md    # ğŸ†• Concept evaluation documentation
â”œâ”€â”€ agent_orchestration/           # ğŸ­ Agent orchestration system
â”‚   â”œâ”€â”€ __init__.py               # Package exports
â”‚   â”œâ”€â”€ orchestrator.py           # Main orchestration classes
â”‚   â”œâ”€â”€ models.py                 # Pydantic models for configuration
â”‚   â”œâ”€â”€ step_handlers.py          # Step-specific execution logic
â”‚   â”œâ”€â”€ schemas/                  # JSON schemas for validation
â”‚   â”‚   â””â”€â”€ workflow_schema.json  # Workflow configuration schema
â”‚   â””â”€â”€ examples/                 # Example workflows and usage
â”‚       â”œâ”€â”€ simple_chat_agent.json
â”‚       â”œâ”€â”€ document_analysis_agent.json
â”‚       â”œâ”€â”€ research_agent.json
â”‚       â””â”€â”€ usage_example.py
â”œâ”€â”€ claude-knowledge/              # ğŸ¤– Claude-specific documentation
â”‚   â”œâ”€â”€ CLAUDE.md                 # Claude guidelines and project overview
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md      # This file - project structure docs
â”‚   â””â”€â”€ README.md                 # Knowledge base overview
â”œâ”€â”€ test/                          # ğŸ§ª Test suite
â”‚   â”œâ”€â”€ __init__.py               # Test package
â”‚   â”œâ”€â”€ test_delete_operations.py # Delete functionality tests
â”‚   â”œâ”€â”€ test_bulk_delete.py       # Bulk delete tests
â”‚   â””â”€â”€ test_chunking_service.py  # Chunking service tests
â”œâ”€â”€ README.md                      # ğŸ“– Main project documentation
â”œâ”€â”€ requirements.txt               # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env.example                   # ğŸ“ Environment template
â”œâ”€â”€ .env                          # ğŸ” Environment configuration (user creates)
â””â”€â”€ CLAUDE.md                     # ğŸ¤– Claude-specific instructions
```

## ğŸš€ How to Use

### First Time Setup
```bash
# 1. Copy environment template
cp .env.example .env

# 2. Follow setup guide
cat setup/README.md

# 3. Verify Supabase setup (if using Supabase)
python setup/setup_supabase.py
```

### Agent Orchestration System (Primary Interface)
```bash
# Run example orchestration workflows
python agent_orchestration/examples/usage_example.py

# Create custom workflows with JSON configuration
```
```python
from agent_orchestration import AgentOrchestrator

# Create orchestrator
orchestrator = AgentOrchestrator()

# Load workflow from JSON
workflow = orchestrator.load_workflow_from_file("my_agent.json")

# Execute with inputs
result = orchestrator.execute_workflow(workflow, {
    "document_path": "/path/to/document.pdf",
    "user_query": "What are the main findings?"
})
```

### LLM Services
```bash
# Run LLM examples
python llm/model_switching_example.py

# Test vision capabilities
python llm/vision_example.py
```
```python
from llm import LLMClientFactory, LLMProvider, VisionProvider

# Create text client
factory = LLMClientFactory()
text_client = factory.create_text_client(LLMProvider.GEMINI)
response = text_client.chat("Hello, world!")

# Create vision client
vision_client = factory.create_vision_client(VisionProvider.GEMINI_VISION)
analysis = vision_client.analyze_image("image.jpg", "Describe this image")
```

### Memory Service
```bash
# Run memory examples
python memory/memory_example.py
```
```python
from memory import create_memory_service
memory_service = create_memory_service("auto")  # Auto-detects available services
```

### Document Processing
```bash
# Run PDF processing examples
python pdf_to_text/example_usage.py
```
```python
from pdf_to_text import PDFToTextService
pdf_service = PDFToTextService()
result = pdf_service.extract_text_with_llm_enhancement("document.pdf")
```

### Text Chunking
```bash
# Run chunking examples
python chunking/example_usage.py
```
```python
from chunking import ChunkingService, ChunkingConfig
chunking_service = ChunkingService(ChunkingConfig(target_size=1000))
chunks = chunking_service.chunk_text("Your long text here...")
```

### Chat Interface
```bash
# Run chat examples
python chat/example_usage.py
```
```python
from chat import ChatService
chat_service = ChatService("gemini")
response = chat_service.chat("Hello, how are you?")
```

### Concept-Based Evaluation System â­ **NEW**
```bash
# Run concept evaluation examples
python examples/concept_evaluation_example.py
```
```python
from prompt.eval_builder import EvaluationBuilder
from prompt.concept_eval_storage import create_concept_eval_storage
from prompt.concept_evaluation_service import ConceptEvaluationService

# Create evaluation
builder = EvaluationBuilder("My Evaluation")
builder.with_prompt_template("Summarize {{content}}")
builder.add_concept_check("must_contain", "Contains facts", "specific data")
builder.add_test_case({"content": "..."}, ["facts_check"])
eval_def = builder.build()

# Run evaluation
storage = create_concept_eval_storage("auto")
service = ConceptEvaluationService(storage)
results = service.run_evaluation(eval_def.to_prompt_evaluation())
```

### Running Tests
```bash
# Test delete operations
python test/test_delete_operations.py

# Test bulk delete functionality  
python test/test_bulk_delete.py

# Test chunking service
python test/test_chunking_service.py
```

## âœ… What Works

### Agent Orchestration System
- âœ… **JSON-driven workflows:** Define complex agent behavior through configuration
- âœ… **Step-by-step execution:** Clear data flow between operations
- âœ… **Service integration:** Combines all building blocks seamlessly
- âœ… **Error handling:** Comprehensive error reporting and graceful fallbacks
- âœ… **Input/output mapping:** Flexible data passing between steps
- âœ… **Example workflows:** Chat agent, document analysis, research agent
- âœ… **Extensible:** Easy to add new step types and handlers
- âœ… **Prompt integration:** Seamless integration with managed prompts
- âœ… **Human-in-the-loop:** Interactive approval and feedback collection
- âœ… **Conditional workflows:** Intelligent branching and routing
- âœ… **Structured responses:** Type-safe LLM outputs with validation

### LLM Abstraction Layer
- âœ… **Multi-provider support:** Gemini and Ollama integration
- âœ… **Text generation:** Chat and completion capabilities
- âœ… **Vision analysis:** Image analysis with Gemini Vision
- âœ… **Embedding generation:** Text vectorization for similarity search
- âœ… **Model switching:** Runtime model changes without client recreation
- âœ… **Factory pattern:** Consistent interface across providers
- âœ… **Configuration management:** Flexible model and parameter configuration

### Prompt Management System
- âœ… **Versioned prompts:** Semantic versioning with lifecycle management
- âœ… **Template system:** Dynamic prompts with Jinja2 variable substitution
- âœ… **Storage backends:** File-based and Supabase storage options
- âœ… **Registry with caching:** Fast access with configurable TTL
- âœ… **Execution logging:** Automatic tracking for evaluation and training
- âœ… **Performance metrics:** Response time, success rate, token usage analysis
- âœ… **A/B testing:** Performance comparison between prompt versions
- âœ… **Training data export:** Generate datasets in JSONL and CSV formats
- âœ… **Template validation:** Validate prompts before deployment
- âœ… **Workflow integration:** Seamless integration with agent orchestration

### Concept-Based Evaluation System â­ **NEW**
- âœ… **LLM-as-Judge:** Automated quality assessment using LLM evaluators
- âœ… **Concept checking:** Must contain/not contain/binary decision validation
- âœ… **Structured test suites:** Template + context + concept checks framework
- âœ… **Builder patterns:** EvaluationBuilder and QuickEvaluationBuilder for easy creation
- âœ… **Pre-built templates:** Common evaluation patterns (accuracy, style, classification)
- âœ… **Storage backends:** File and Supabase storage with evaluation history
- âœ… **Quality gates:** Pass/fail thresholds for automated quality control
- âœ… **Agent integration:** Built-in concept_evaluation step type
- âœ… **Comprehensive reporting:** Scores, grades, recommendations, and detailed results
- âœ… **Multi-judge support:** Gemini, Anthropic, and Ollama as evaluation judges
- âœ… **CSV import/export:** Import test cases and export results
- âœ… **Chain-of-thought reasoning:** Judges provide detailed reasoning for decisions

### Document Processing
- âœ… **PDF extraction:** Traditional and LLM-enhanced text extraction
- âœ… **Vision fallback:** LLM vision for challenging PDFs
- âœ… **Content enhancement:** LLM-powered formatting improvement
- âœ… **Semantic analysis:** Document classification and key point extraction
- âœ… **RAG integration:** Automatic chunking for vector databases
- âœ… **Configurable options:** Flexible extraction strategies

### Text Chunking Service
- âœ… **Boundary preservation:** Respects paragraphs, sentences, and words
- âœ… **Configurable strategies:** Target size with tolerance ranges
- âœ… **Fallback hierarchy:** Graceful degradation from paragraph â†’ sentence â†’ word â†’ character
- âœ… **Integration ready:** Used by PDF service for RAG applications
- âœ… **Semantic awareness:** Preserves meaning across chunk boundaries

### Memory Service Features
- âœ… **Auto-detection:** Finds available services (Neo4j/Supabase)
- âœ… **Neo4j support:** Graph database with relationships
- âœ… **Supabase + pgvector:** PostgreSQL with vector similarity search
- âœ… **Vector search:** Semantic similarity with embeddings
- âœ… **Hybrid search:** Combined vector and text search (Supabase)
- âœ… **CRUD operations:** Create, read, update, delete memories
- âœ… **Bulk operations:** Efficient multi-delete with single query
- âœ… **Search-based delete:** Delete by query criteria
- âœ… **Metadata support:** Structured data with JSON serialization
- âœ… **Pydantic models:** Type-safe data validation and serialization

### Chat Interface
- âœ… **Multi-provider support:** Ollama and Gemini integration
- âœ… **History management:** Automatic conversation tracking
- âœ… **Message format:** Standardized ChatMessage structure
- âœ… **Backward compatibility:** Legacy adapter for existing code

### Testing & Quality
- âœ… **Comprehensive tests:** All core operations validated
- âœ… **Error handling:** Invalid inputs, missing services, network issues
- âœ… **Data integrity:** Relationships cleaned up, search consistency
- âœ… **Performance:** Bulk operations use optimized queries
- âœ… **Type safety:** Pydantic models throughout for validation

## ğŸ”§ Configuration

### Environment Variables
```bash
# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687      # or your Neo4j server
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password

# Supabase Configuration (with pgvector)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key      # NOT service role key

# AI/ML Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2     # Sentence transformer model

# Prompt Management Configuration
PROMPT_STORAGE_BACKEND=supabase      # or 'file' or 'auto'
PROMPT_STORAGE_PATH=./prompts        # for file backend
PROMPT_CACHE_TTL=3600               # cache timeout in seconds
PROMPT_EVALUATION_ENABLED=true      # enable execution logging
```

### Setup Instructions
For detailed setup instructions, see the setup folder:

```bash
# Complete setup guide
cat setup/README.md

# Supabase-specific setup
cat setup/SUPABASE_SETUP.md

# Verify Supabase configuration
python setup/setup_supabase.py
```

The setup process includes:
1. **Environment Configuration** - Copy .env.example to .env
2. **Database Setup** - Choose between Supabase (recommended) or Neo4j
3. **API Keys** - Configure Ollama, Gemini, or other LLM services
4. **Prompt Storage** - Configure prompt management backend (file or Supabase)
5. **Verification** - Test all connections and functionality

## ğŸ“¦ Benefits of Current Structure

1. **Easy Setup:** Dedicated setup folder with comprehensive guides
2. **Modularity:** Clear separation of concerns (setup, memory, chat, tests)
3. **Maintainability:** Easier to find and modify code
4. **User-Friendly:** New users can get started quickly with setup/README.md
5. **Testing:** Isolated test suite with comprehensive coverage
6. **Reusability:** Memory package can be imported elsewhere
7. **Scalability:** Easy to add new services (Redis, Elasticsearch, etc.)
8. **Clean imports:** Proper Python package structure
9. **Documentation:** Multiple levels of documentation for different needs
10. **Production-Ready:** Includes environment templates, verification scripts

## ğŸ¯ Project Philosophy

This project follows a **learning-focused development approach**:

- **Educational:** Each component helps users understand LLM project patterns
- **Well-documented:** Clear explanations and examples throughout
- **Modular:** Easy to extend, modify, and understand
- **Partnership-focused:** Claude acts as a thoughtful development partner

The codebase is now production-ready with a clean, organized structure that prioritizes both functionality and user experience! ğŸ‰