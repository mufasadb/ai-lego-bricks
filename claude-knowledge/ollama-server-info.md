# Ollama Server Information

## Remote Server Details
- **Server URL**: ollama.beachysapp.com
- **Port**: Default (11434)
- **Full URL**: http://ollama.beachysapp.com:11434

## Available Models
- **VL Model**: qwen2.5vlv (or similar variant)
- **Text Models**: mistral, llama variants, etc.

## Configuration
When using Ollama in the codebase, set:
```
OLLAMA_URL=http://ollama.beachysapp.com:11434
```

## Usage Notes
- The server is running and accessible remotely
- Both vision-language and text models are available
- Use this for testing multi-model agents and workflows